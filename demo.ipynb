{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cardiovascular age\n",
    "\n",
    "### Loading the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lCF76KJpP7kI"
   },
   "outputs": [],
   "source": [
    "#!pip install --user -q scipy optuna catboost scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y4hQ_g7NPnr6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import optuna\n",
    "from sklearn import linear_model, ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "np.random.seed(1) # Deterministic seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining our hyperparameter searching function, you basically feed a x, y dataset and it will return the best catboost model after n_trial hyperpameter searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3lbkK7I7Hj-i"
   },
   "outputs": [],
   "source": [
    "def train_with_hyp_search(x_trial, y_trial, esttype='catb', n_trials=30,\n",
    "                          optuna_sql_path='/dev/shm/optuna.sqlite3',\n",
    "                          optuna_storage_dir='/tmp/optuna_pkls'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_trial : array_like\n",
    "        Features to train\n",
    "    y_trial : array_like\n",
    "        Target (age) to train\n",
    "    esttype : str\n",
    "        Estimator name, can be 'catb' (for catboost) or 'lasso' or\n",
    "        'ridge' or 'en' (for elastic net) or 'rf' (for random forests)\n",
    "    optuna_sql_path : str\n",
    "        Path to save optuna sql database\n",
    "    optuna_storage_dir : str\n",
    "        Path to save optuna model pickles\n",
    "    \"\"\"\n",
    "    \n",
    "    x_trial_train, x_trial_test, y_trial_train, y_trial_test = train_test_split(x_trial, y_trial, test_size=0.1, random_state=0)\n",
    "    if esttype == 'catb':\n",
    "        x_trial_train, x_trial_val, y_trial_train, y_trial_val = train_test_split(x_trial_train, y_trial_train, test_size=0.1, random_state=1)\n",
    "\n",
    "    def objective(trial):\n",
    "        successful_trials_so_far = len([t for t in study.trials if t.state.name == 'COMPLETE'])\n",
    "        if successful_trials_so_far >= n_trials:\n",
    "            study.stop()\n",
    "            print('Maximum number of trials reached, prunning')\n",
    "            raise optuna.TrialPruned()\n",
    "        print(f\"Running trial {trial.number}\")\n",
    "\n",
    "        if esttype == 'catb':\n",
    "            param = {\n",
    "                'iterations': 100_000,\n",
    "                'early_stopping_rounds': trial.suggest_int(\"early_stopping_rounds\", 50, 100),\n",
    "                'verbose': 1000,\n",
    "                'random_seed': successful_trials_so_far,\n",
    "                #'task_type': 'GPU',\n",
    "            }\n",
    "\n",
    "            creg = CatBoostRegressor(**param)\n",
    "            creg.fit(x_trial_train, y_trial_train,\n",
    "                eval_set=(x_trial_val, y_trial_val)\n",
    "            )\n",
    "\n",
    "        elif esttype == 'lasso':\n",
    "            alpha = trial.suggest_float(\"alpha\", 0, 10)\n",
    "\n",
    "            creg = linear_model.Lasso(alpha=alpha)\n",
    "            creg.fit(x_trial_train, y_trial_train)\n",
    "\n",
    "        elif esttype == 'ridge':\n",
    "            alpha = trial.suggest_float(\"alpha\", 0, 10)\n",
    "\n",
    "            creg = linear_model.Ridge(alpha=alpha)\n",
    "            creg.fit(x_trial_train, y_trial_train)\n",
    "\n",
    "        elif esttype == 'en':\n",
    "            alpha = trial.suggest_float(\"alpha\", 0, 10)\n",
    "            l1_ratio = trial.suggest_float(\"l1_ratio\", 0, 1)\n",
    "\n",
    "            creg = linear_model.ElasticNet(alpha=alpha,\n",
    "                l1_ratio=l1_ratio)\n",
    "            creg.fit(x_trial_train, y_trial_train)\n",
    "\n",
    "        elif esttype == 'rf':\n",
    "            n_estimators = trial.suggest_int(\"alpha\", 100, 1000)\n",
    "\n",
    "            creg = ensemble.RandomForestRegressor(\n",
    "                n_estimators=n_estimators)\n",
    "            creg.fit(x_trial_train, y_trial_train)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Invalid estimator type')\n",
    "        \n",
    "        y_trial_pred = creg.predict(x_trial_test)\n",
    "        diff = y_trial_pred - y_trial_test\n",
    "        err = np.abs(diff).mean()\n",
    "\n",
    "        trial.set_user_attr(\"err\", err)\n",
    "        print('error on hyp search validation:', err)\n",
    "\n",
    "        best_estimator_performance = np.inf\n",
    "        try:\n",
    "            best_estimator_performance = study.best_trial.values[0]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if best_estimator_performance >= err:\n",
    "            print('Best estimator so far. Saving estimator, started.')\n",
    "            with open(f\"{os.path.join(optuna_storage_dir, str(trial.number))}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(creg, f)\n",
    "            print('Saving estimator, done.')\n",
    "        else:\n",
    "            print('Not the best estimator so far.')\n",
    "\n",
    "        print(f\"Finished trial {trial.number}\")\n",
    "        return err\n",
    "\n",
    "    optuna_storage_dir = os.path.join(optuna_storage_dir, esttype)\n",
    "    os.makedirs(optuna_storage_dir, exist_ok=True)\n",
    "\n",
    "    optuna_storage = optuna.storages.RDBStorage(url=\"sqlite:///\"+optuna_sql_path, engine_kwargs={\"connect_args\": {\"timeout\": 600}})\n",
    "    try:\n",
    "        optuna.delete_study(storage=optuna_storage, study_name=esttype)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    study = optuna.create_study(storage=optuna_storage,\n",
    "                                study_name=esttype, direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=1))\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Loading best trial:\", study.best_params, 'started')\n",
    "    with open(f\"{os.path.join(optuna_storage_dir, str(study.best_trial.number))}.pkl\", \"rb\") as f:\n",
    "        best_creg = pickle.load(f)\n",
    "    print(\"Loading best trial:\", study.best_params, 'done')\n",
    "\n",
    "    return best_creg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "Load the dataset for healthy patients and check for NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kr9PmmosPjXN",
    "outputId": "e8f691cd-8e33-4fef-86b9-5eb02e182175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NAs 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/synthetic_db_healthy.csv')\n",
    "print('Number of NAs', df.isna().any(1).sum())\n",
    "x_all, y_all = df.iloc[:, df.columns!='age_at_MRI'], df['age_at_MRI'], \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the features and targets (ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QUwv1VA4JCgm"
   },
   "outputs": [],
   "source": [
    "x_all, y_all = df.iloc[:, df.columns!='age_at_MRI'], df['age_at_MRI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Now fit catboost with hyperparameter searching doing n_trials paramater searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icD6yFbf7_XQ",
    "outputId": "15ae9920-6050-49e6-b74e-17c553c1ec55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-15 16:54:48,940]\u001b[0m A new study created in RDB with name: catb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 0\n",
      "Learning rate set to 0.003698\n",
      "0:\tlearn: 7.2927696\ttest: 6.7203045\tbest: 6.7203045 (0)\ttotal: 65.2ms\tremaining: 1h 48m 41s\n",
      "1000:\tlearn: 5.3641452\ttest: 5.4879250\tbest: 5.4879250 (1000)\ttotal: 4.68s\tremaining: 7m 43s\n",
      "2000:\tlearn: 4.8505237\ttest: 5.3400868\tbest: 5.3400868 (2000)\ttotal: 9.16s\tremaining: 7m 28s\n",
      "3000:\tlearn: 4.4107673\ttest: 5.2818156\tbest: 5.2815372 (2996)\ttotal: 13.6s\tremaining: 7m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-15 16:55:06,376]\u001b[0m Trial 0 finished with value: 4.56010275406753 and parameters: {'early_stopping_rounds': 71}. Best is trial 0 with value: 4.56010275406753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (71 iterations wait)\n",
      "\n",
      "bestTest = 5.257545066\n",
      "bestIteration = 3671\n",
      "\n",
      "Shrink model to first 3672 iterations.\n",
      "error on hyp search validation: 4.56010275406753\n",
      "Best estimator so far. Saving estimator, started.\n",
      "Saving estimator, done.\n",
      "Finished trial 0\n",
      "Loading best trial: {'early_stopping_rounds': 71} started\n",
      "Loading best trial: {'early_stopping_rounds': 71} done\n"
     ]
    }
   ],
   "source": [
    "n_trials = 30\n",
    "\n",
    "best_creg  = train_with_hyp_search(x_train, y_train, esttype='catb', n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of results\n",
    "\n",
    "Now, we evaluate the MAE and R² on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bl6Mn72o_GmR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set 4.527648784528185\n",
      "R² on test set -0.4998542892003246\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_creg.predict(x_test)\n",
    "\n",
    "mae = np.abs(y_pred - y_test).mean()\n",
    "print(\"MAE on test set\", mae)\n",
    "\n",
    "se = (y_pred - y_test)**2\n",
    "ss_res = se.sum()\n",
    "ss_total = ((y_pred - y_train.mean())**2).sum()\n",
    "rsq = 1 - ss_res / ss_total\n",
    "    \n",
    "print(\"R² on test set\", rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the delta for patients with risk factors\n",
    "\n",
    "We start by loading the dataset of patients with risk factors and checking for NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bk9HSKt_TCHI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf = pd.read_csv('data/synthetic_db_with_risk_factors.csv')\n",
    "x_rf = df_rf[x_all.columns]\n",
    "y_rf = df_rf['age_at_MRI']\n",
    "df_rf.isna().any(1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating the deltas, it's necessary to define the function that does the bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bias correction to a previosly trainer estimator\n",
    "class BiasCorrectEstimator:\n",
    "    def __init__(self, est, x_sval_bc, y_sval_bc):\n",
    "        self.est = est\n",
    "        \n",
    "        x_sval_bc = np.array(x_sval_bc)\n",
    "        y_sval_bc = np.array(y_sval_bc).reshape(-1)\n",
    "        \n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(y_sval_bc.reshape((-1, 1)), est.predict(x_sval_bc).reshape(-1))\n",
    "        self.intercept = reg.intercept_\n",
    "        self.coef = reg.coef_.item()\n",
    " \n",
    "    def predict(self, x_pred, y_pred=None):\n",
    "        x_pred = np.array(x_pred)\n",
    "        pred = self.est.predict(x_pred)\n",
    "        pred = (pred - self.intercept) / self.coef\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then predict and calculate the deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qwB6wTvaR-v6"
   },
   "outputs": [],
   "source": [
    "best_creg_bc = BiasCorrectEstimator(best_creg, x_rf, y_rf)\n",
    "y_rf_pred = best_creg_bc.predict(x_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the new dataset for analysis in the next notebook (phenotype analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_with_deltas = df_rf.copy()\n",
    "df_rf_with_deltas['ca_delta'] = y_rf_pred - y_rf\n",
    "df_rf_with_deltas.to_csv('data/synthetic_db_with_risk_factors_and_deltas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: fit the regression\n",
    "\n",
    "This will be covered in more detail (and with propensity matching procudures) in the next notebook using R. However, if desired, it's already possible to run the regression using Python `statsmodels` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dMbTCCaDVUoJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>ca_delta</td>     <th>  R-squared:         </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7.788</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 15 Aug 2022</td> <th>  Prob (F-statistic):</th>  <td>2.46e-07</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:55:12</td>     <th>  Log-Likelihood:    </th> <td>-1.2648e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 34137</td>      <th>  AIC:               </th>  <td>2.530e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 34131</td>      <th>  BIC:               </th>  <td>2.530e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    0.1341</td> <td>    0.455</td> <td>    0.294</td> <td> 0.768</td> <td>   -0.759</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rf_diabetes</th>     <td>    0.2542</td> <td>    0.255</td> <td>    0.998</td> <td> 0.318</td> <td>   -0.245</td> <td>    0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>             <td>   -0.6261</td> <td>    0.113</td> <td>   -5.541</td> <td> 0.000</td> <td>   -0.848</td> <td>   -0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rf_diabetes:sex</th> <td>   -0.0368</td> <td>    0.345</td> <td>   -0.107</td> <td> 0.915</td> <td>   -0.714</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_at_MRI</th>      <td>   -0.0436</td> <td>    0.028</td> <td>   -1.579</td> <td> 0.114</td> <td>   -0.098</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_at_MRI ^ 2</th>  <td>    0.0459</td> <td>    0.027</td> <td>    1.725</td> <td> 0.084</td> <td>   -0.006</td> <td>    0.098</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>99.631</td> <th>  Durbin-Watson:     </th> <td>   1.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  81.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.049</td> <th>  Prob(JB):          </th> <td>1.78e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.781</td> <th>  Cond. No.          </th> <td>    782.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               ca_delta   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                  0.001\n",
       "Method:                 Least Squares   F-statistic:                     7.788\n",
       "Date:                Mon, 15 Aug 2022   Prob (F-statistic):           2.46e-07\n",
       "Time:                        16:55:12   Log-Likelihood:            -1.2648e+05\n",
       "No. Observations:               34137   AIC:                         2.530e+05\n",
       "Df Residuals:                   34131   BIC:                         2.530e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           0.1341      0.455      0.294      0.768      -0.759       1.027\n",
       "rf_diabetes         0.2542      0.255      0.998      0.318      -0.245       0.753\n",
       "sex                -0.6261      0.113     -5.541      0.000      -0.848      -0.405\n",
       "rf_diabetes:sex    -0.0368      0.345     -0.107      0.915      -0.714       0.640\n",
       "age_at_MRI         -0.0436      0.028     -1.579      0.114      -0.098       0.011\n",
       "age_at_MRI ^ 2      0.0459      0.027      1.725      0.084      -0.006       0.098\n",
       "==============================================================================\n",
       "Omnibus:                       99.631   Durbin-Watson:                   1.981\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               81.736\n",
       "Skew:                           0.049   Prob(JB):                     1.78e-18\n",
       "Kurtosis:                       2.781   Cond. No.                         782.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = smf.ols(formula='ca_delta ~ rf_diabetes*sex + age_at_MRI + age_at_MRI^2', data=df_rf_with_deltas).fit()\n",
    "\n",
    "reg.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cardiac ageing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
